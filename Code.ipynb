{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c27deb8-86c6-49ea-a289-b1a7cd77b2a4",
   "metadata": {},
   "source": [
    "## HARD_LAB CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5af616f-92b3-4272-b2e9-22bdc28109ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aakanksha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aakanksha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/aakanksha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Creating word frequency dictionaries...\n",
      "Converting tweets to numerical features...\n",
      "Vocabulary size: 466257\n",
      "Training the classifier...\n",
      "Loading testing data...\n",
      "\n",
      "Accuracy: 77.68%\n",
      "\n",
      "Enter new tweet for sentiment analysis:\n",
      "Type 'quit' to exit\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a tweet to analyze:  This is so innovative and creative idea.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment is Positive\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a tweet to analyze:  I hate this idea.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment is Negative\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a tweet to analyze:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using the tweet sentiment analyzer.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to preprocess file\n",
    "def text_preprocessing(text):\n",
    "    # Convert tweets to lower case\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs and links\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove punctuation marks\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Remove HTML and XML tags\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "\n",
    "    # Tokenize the tweets into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Initialize WordNet Lemmatizer\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    # Remove stop words and lemmatize each word\n",
    "    stops = set(stopwords.words('english'))\n",
    "    words_filter = [lem.lemmatize(w) for w in words if w not in stops]\n",
    "\n",
    "    # Return the processed words as a single string (needed for CountVectorizer)\n",
    "    return ' '.join(words_filter)\n",
    "\n",
    "# Function to load tweets from a file and preprocess them\n",
    "def load_tweets(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        tweets = file.readlines()\n",
    "    # Preprocess each tweet and return them as a list of strings\n",
    "    return [text_preprocessing(tweet) for tweet in tweets]\n",
    "\n",
    "# Function to create word frequency dictionary\n",
    "def word_frequency_dict(tweets):\n",
    "    word_frequency = defaultdict(int)\n",
    "    for tweet in tweets:\n",
    "        words = tweet.split()  # Now `tweet` is a string, so splitting it works\n",
    "        for word in words:\n",
    "            word_frequency[word] += 1\n",
    "    return dict(word_frequency)\n",
    "\n",
    "# Load training data (positive and negative tweets)\n",
    "print(\"Loading training data...\")\n",
    "train_Pos_tweets = load_tweets(\"train_Pos.en\")\n",
    "train_Neg_tweets = load_tweets(\"train_Neg.en\")\n",
    "\n",
    "# Create word frequency dictionaries for both positive and negative tweets\n",
    "print(\"Creating word frequency dictionaries...\")\n",
    "pos_word_freq = word_frequency_dict(train_Pos_tweets)\n",
    "neg_word_freq = word_frequency_dict(train_Neg_tweets)\n",
    "\n",
    "# Combine all training tweets and create labels (1 for positive, 0 for negative)\n",
    "all_train_tweets = train_Pos_tweets + train_Neg_tweets\n",
    "train_labels = np.array([1] * len(train_Pos_tweets) + [0] * len(train_Neg_tweets))\n",
    "\n",
    "# Convert tweets to numerical features using CountVectorizer with ngram\n",
    "print(\"Converting tweets to numerical features...\")\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(all_train_tweets)\n",
    "\n",
    "# Get vocabulary size\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "print(f\"Vocabulary size: {len(vocabulary)}\")\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "print(\"Training the classifier...\")\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, train_labels)\n",
    "\n",
    "# Load test data (positive and negative tweets)\n",
    "print(\"Loading testing data...\")\n",
    "test_Pos_tweets = load_tweets(\"ttestPos.en\")\n",
    "test_Neg_tweets = load_tweets(\"ttestNeg.en\")\n",
    "\n",
    "# Combine all test tweets and create labels\n",
    "all_test_tweets = test_Pos_tweets + test_Neg_tweets\n",
    "test_labels = np.array([1] * len(test_Pos_tweets) + [0] * len(test_Neg_tweets))\n",
    "\n",
    "# Transform test data using the trained vectorizer\n",
    "X_test = vectorizer.transform(all_test_tweets)\n",
    "\n",
    "# Make predictions using the classifier\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy of the model\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Function to predict the sentiment of a new tweet\n",
    "def predict_new_tweet_sentiment(new_tweet):\n",
    "    # Preprocess the new tweet\n",
    "    processed_tweet = text_preprocessing(new_tweet)\n",
    "    # Vectorize the preprocessed tweet\n",
    "    tweet_vector = vectorizer.transform([processed_tweet])\n",
    "    # Predict the sentiment\n",
    "    prediction = classifier.predict(tweet_vector)\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
    "\n",
    "# Interactive loop for predicting the sentiment of new tweets\n",
    "print(\"\\nEnter new tweet for sentiment analysis:\")\n",
    "print(\"Type 'quit' to exit\")\n",
    "\n",
    "while True:\n",
    "    tweet_input = input(\"\\nEnter a tweet to analyze: \")\n",
    "    if tweet_input.lower() == 'quit':\n",
    "        print(\"Thank you for using the tweet sentiment analyzer.\")\n",
    "        break\n",
    "    sentiment = predict_new_tweet_sentiment(tweet_input)\n",
    "    print(f\"Sentiment is {sentiment}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
